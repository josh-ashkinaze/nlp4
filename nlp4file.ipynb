{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89109b4",
   "metadata": {},
   "source": [
    "# Load up tokenizers and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cf331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5075bec1f4734b53a1631f55efbfd6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dcd0446310493193a933f927df28f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import login\n",
    "import accelerate\n",
    "import random\n",
    "import sentencepiece\n",
    "random.seed(42)\n",
    "# access_token_read = \"asd\"\n",
    "# login(token = access_token_read)\n",
    "\n",
    "models = {\n",
    "    'gpt2':pipeline('text-generation', model='gpt2'), \n",
    "    'gemma-2b':{'tokenizer':AutoTokenizer.from_pretrained(\"google/gemma-2b\"),\n",
    "               'model':AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")},\n",
    "    'flan-t5':{'tokenizer':T5Tokenizer.from_pretrained(\"google/flan-t5-large\"),\n",
    "               'model':T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")},\n",
    "    'opt-2.7b':pipeline('text-generation', model='facebook/opt-2.7b'), \n",
    "    'mistral':pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.read_json(\"hellaswag_val.300.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbc282",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b53b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 24923.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT NAME: minimal\n",
      "INSTRUCTIONS\n",
      "Choose the best option to complete this sentence.\n",
      "\n",
      "SENTENCE\n",
      "A man is sitting on a roof. he\n",
      "\n",
      "Answer 0: is using wrap to wrap a pair of skis.\n",
      "Answer 1: is ripping level tiles off.\n",
      "Answer 2: is holding a rubik's cube.\n",
      "Answer 3: starts pulling up roofing on a roof.\n",
      "\n",
      "RETURN\n",
      "Return the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROMPT NAME: reasonable\n",
      "INSTRUCTIONS\n",
      "Your job is to complete a sentence with the most reasonable ending.\n",
      "\n",
      "SENTENCE\n",
      "A man is sitting on a roof. he\n",
      "\n",
      "Answer 0: is using wrap to wrap a pair of skis.\n",
      "Answer 1: is ripping level tiles off.\n",
      "Answer 2: is holding a rubik's cube.\n",
      "Answer 3: starts pulling up roofing on a roof.\n",
      "\n",
      "RETURN\n",
      "Return the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROMPT NAME: logical\n",
      "INSTRUCTIONS\n",
      "Your job is to complete a sentence with the most logical ending.\n",
      "\n",
      "SENTENCE\n",
      "A man is sitting on a roof. he\n",
      "\n",
      "Answer 0: is using wrap to wrap a pair of skis.\n",
      "Answer 1: is ripping level tiles off.\n",
      "Answer 2: is holding a rubik's cube.\n",
      "Answer 3: starts pulling up roofing on a roof.\n",
      "\n",
      "RETURN\n",
      "Return the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROMPT NAME: cot\n",
      "INSTRUCTIONS\n",
      "Your job is to complete a sentence with the most reasonable or logical ending. Think step by step to arrive at your answer\n",
      "\n",
      "SENTENCE\n",
      "A man is sitting on a roof. he\n",
      "\n",
      "Answer 0: is using wrap to wrap a pair of skis.\n",
      "Answer 1: is ripping level tiles off.\n",
      "Answer 2: is holding a rubik's cube.\n",
      "Answer 3: starts pulling up roofing on a roof.\n",
      "\n",
      "RETURN\n",
      "Return the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROMPT NAME: context\n",
      "INSTRUCTIONS\n",
      "Your job is to complete a sentence with the most reasonable ending.\n",
      "\n",
      "EXAMPLES\n",
      "-Sentence: A camera pans away from a road and shows a person's feet moving around. several shots\n",
      "-Correct Answer: are shown of people tying their shoes, hitting a button, and checking a watch.\n",
      "\n",
      "-Sentence: There's a woman with red colored hair wearing a black tank top and printed black tights skating on roller blades through the streets of a city. The streets don't have any cars but people are riding bikes or skateboarding. the woman\n",
      "-Correct Answer: swiftly skates through the crowded streets as she passes by several tourists walking leisurely.\n",
      "\n",
      "\n",
      "SENTENCE\n",
      "A man is sitting on a roof. he\n",
      "\n",
      "Answer 0: is using wrap to wrap a pair of skis.\n",
      "Answer 1: is ripping level tiles off.\n",
      "Answer 2: is holding a rubik's cube.\n",
      "Answer 3: starts pulling up roofing on a roof.\n",
      "\n",
      "RETURN\n",
      "Return the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [01:17<1:01:52, 12.63s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "\n",
    "\n",
    "# NOTE: human_context has in-context examples\n",
    "instructions_dict = {\n",
    "    'minimal':\"INSTRUCTIONS\\nChoose the best option to complete this sentence.\", \n",
    "    'reasonable':\"INSTRUCTIONS\\nYour job is to complete a sentence with the most reasonable ending.\", \n",
    "    'logical':\"INSTRUCTIONS\\nYour job is to complete a sentence with the most logical ending.\", \n",
    "    'cot':\"INSTRUCTIONS\\nYour job is to complete a sentence with the most reasonable or logical ending. Think step by step to arrive at your answer\", \n",
    "    'context':\"INSTRUCTIONS\\nYour job is to complete a sentence with the most reasonable ending.\\n\\nEXAMPLES\\n[examples_here]\"\n",
    "}\n",
    "return_str = \"RETURN\\nReturn the number corresponding to the best option in a json format like {'best_option':best_option}. Return nothing else.\"\n",
    "\n",
    "\n",
    "def get_examples(df, num_examples=2):\n",
    "    samples = df.sample(n=num_examples)\n",
    "    \n",
    "    result_strings = []\n",
    "    for idx, row in samples.iterrows():\n",
    "        context = row['ctx']\n",
    "        options = row['endings']  \n",
    "        cor_idx = row['label']  \n",
    "        cor_opt = options[cor_idx]\n",
    "\n",
    "        result_string = f\"-Sentence: {context}\\n-Correct Answer: {cor_opt}\\n\"\n",
    "        result_strings.append(result_string)\n",
    "    \n",
    "    return \"\\n\".join(result_strings)\n",
    "\n",
    "\n",
    "def make_prompt(instructions, cntx, possible):\n",
    "    possible_str = \"\".join([f\"Answer {i}: {endings[i]}\\n\" for i in range(len(endings))])\n",
    "    pr_str = f\"\"\"{instructions}\\n\\nSENTENCE\\n{cntx}\\n\\n{possible_str}\\n{return_str}\"\"\"\n",
    "    return pr_str\n",
    "    \n",
    "\n",
    "def run_model(text, model_name):\n",
    "    try:\n",
    "        if model_name in ['gpt2', 'opt-2.7b']:\n",
    "            generator = models[model_name]\n",
    "            output = generator(text, max_new_tokens=100, num_return_sequences=1, device='cuda')\n",
    "            return output[0]['generated_text']\n",
    "        elif model_name in ['gemma-2b', 'flan-t5', 'mistral']:\n",
    "            if model_name == 'mistral':\n",
    "                text = \"[INST]\" + text + \"[/INST]\"\n",
    "            model_stuff = models[model_name]\n",
    "            tok, mod = model_stuff['tokenizer'], model_stuff['model']\n",
    "            input_ids = tok(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "            outputs = mod.generate(**input_ids, max_new_tokens=100)\n",
    "            output_decode = tok.decode(outputs[0])\n",
    "            if model_name == 'gemma-2b':\n",
    "                output_decode = output_decode.replace(text, \"\")\n",
    "                output_decode = output_decode.replace(\"<bos>\", \"\")\n",
    "                output_decode = output_decode.strip()\n",
    "            return output_decode\n",
    "    except Exception as e:\n",
    "        return f'{{\"best_answer\": \"{random.choice([0, 1, 2, 3, 4])}\"}}'\n",
    "\n",
    "data = pd.read_json(\"hellaswag_val.300.jsonl\", lines=True)\n",
    "\n",
    "\n",
    "\n",
    "######### JUST PRINT PROMPTS #########\n",
    "\n",
    "p_data = []\n",
    "counter = 0\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    if counter < 1:\n",
    "        inst_id = row['ind']\n",
    "        ctx = row['ctx']\n",
    "        endings = row['endings'] \n",
    "        correct = row['label']\n",
    "        for (ins_name, ins_text) in instructions_dict.items():\n",
    "            if ins_name == \"context\":\n",
    "                examples = get_examples(data, 2)\n",
    "                ins_text = ins_text.replace(\"[examples_here]\", examples)\n",
    "            \n",
    "            print(f\"PROMPT NAME: {ins_name}\")\n",
    "            print(make_prompt(ins_text, ctx, endings))\n",
    "            print(\"\\n\"*4)\n",
    "\n",
    "    counter+=1\n",
    "\n",
    "            \n",
    "######### RUN FOR REAL #########\n",
    "\n",
    "p_data = []\n",
    "counter = 0\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    inst_id = row['ind']\n",
    "    ctx = row['ctx']\n",
    "    endings = row['endings'] \n",
    "    correct = row['label']\n",
    "    for (ins_name, ins_text) in instructions_dict.items():\n",
    "        if ins_name == \"context\":\n",
    "            examples = get_examples(data, 2)\n",
    "            ins_text = ins_text.replace(\"[examples_here]\", examples)\n",
    "        for model_name in list(models.keys()):\n",
    "            prompt_input = make_prompt(ins_text, ctx, endings)\n",
    "            pred = run_model(prompt_input, model_name)\n",
    "            pred_data = {'inst_id':inst_id, 'prompt': ins_name, 'correct':correct, 'pred':pred, 'model_name':model_name}\n",
    "\n",
    "        \n",
    "prompt_data = pd.DataFrame(p_data)\n",
    "prompt_data.to_csv(\"prompt_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "463e454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(x):\n",
    "    answers = {'0', '1', '2', '3', '4'}\n",
    "\n",
    "    try:\n",
    "        asd = eval(x)\n",
    "        if list(ad.keys()) == ['best_answer']:\n",
    "            if asd['best_answer'] in answers:\n",
    "                return asd['best_answer']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for char in x:\n",
    "        if char in answers:\n",
    "            return char\n",
    "    return random.choice(list(answers))\n",
    "        \n",
    "prompt_data['clean'] = prompt_data['pred'].apply(parse_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56e9c693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "3     6\n",
       "1     3\n",
       "2     1\n",
       "4     1\n",
       "Name: clean, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_data['clean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe33c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"hellaswag_val.300.jsonl\", lines=True)\n",
    "samp_rows=  data.sample(2)\n",
    "samp1 = samp_rows.iloc[0]['ctx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea53171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ind', 'activity_label', 'ctx_a', 'ctx_b', 'ctx', 'split', 'split_type',\n",
       "       'label', 'endings', 'source_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f819619f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_543758/3289350417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd22af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_hellaswag_examples(df, num_examples=2):\n",
    "    # Randomly sample two rows from the DataFrame\n",
    "    samples = df.sample(n=num_examples)\n",
    "    \n",
    "    result_strings = []\n",
    "    for _, row in samples.iterrows():\n",
    "        context = row['ctx']\n",
    "        options = row['endings']  \n",
    "        formatted_options = \"\\n\".join([f\"- Option {i+1}: {opt}\" for i, opt in enumerate(options)])\n",
    "        \n",
    "        result_string = f\"CONTEXT: {context}\\nOPTIONS:\\n{formatted_options}\\n\"\n",
    "        result_strings.append(result_string)\n",
    "    \n",
    "    # Join the two example strings with a newline for separation\n",
    "    return \"\\n\".join(result_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4314ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT: A graphic introduces the hand car wash video. The car is washed first gently with soap. next\n",
      "OPTIONS:\n",
      "- Option 1: is a clean car wash video.\n",
      "- Option 2: , two cars slowly drive by.\n",
      "- Option 3: , the tires are soaped and washed thoroughly.\n",
      "- Option 4: , it is shown from behind.\n",
      "\n",
      "CONTEXT: A sea is shown with a green forest on seashore. Blond man is standing in seashore and talking to the camera and surfing big waves on the sea. man\n",
      "OPTIONS:\n",
      "- Option 1: is on ocean and swimming in white water snapping his head.\n",
      "- Option 2: is snowboarding up in the sea.\n",
      "- Option 3: is doing flips in the waters and on the rocks and he be water surfing.\n",
      "- Option 4: is walking on seashore through a lot of people and talking to the camera and holding an award and talking about surfing the seashore.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_hellaswag_examples(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4652ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT: She then shows an appliance on the table and tilts it upwards. She turns a dial on the appliance and sets it back down. she\n",
      "ANSWER: picks the knife back up and places it on the appliance.\n",
      "\n",
      "CONTEXT: A man is kneeling on the ice with another beside hide pulling string out of a hole. they\n",
      "ANSWER: continue to pull the string while the man beside him grabs a hook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_examples(df, num_examples=2):\n",
    "    samples = df.sample(n=num_examples)\n",
    "    \n",
    "    result_strings = []\n",
    "    for idx, row in samples.iterrows():\n",
    "        context = row['ctx']\n",
    "        options = row['endings']  \n",
    "        cor_idx = row['label']  \n",
    "        cor_opt = options[cor_idx]\n",
    "\n",
    "        result_string = f\"CONTEXT: {context}\\nANSWER: {cor_opt}\\n\"\n",
    "        result_strings.append(result_string)\n",
    "    \n",
    "    return \"\\n\".join(result_strings)\n",
    "\n",
    "print(get_examples(data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ab022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b78eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
